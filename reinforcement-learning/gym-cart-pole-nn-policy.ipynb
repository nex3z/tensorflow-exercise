{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "from plot_utils import plot_animation\n",
    "from cart_pole_utils import play_one_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 47\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    layers.Dense(5, activation='elu', input_shape=[4]),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs = [ 0.02232422 -0.02619596  0.02769897  0.00666565]\n",
      "prob = [[0.50284725]]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "env.seed(SEED)\n",
    "\n",
    "obs = env.reset()\n",
    "print(f\"obs = {obs}\")\n",
    "\n",
    "prob = model.predict(obs[np.newaxis])\n",
    "print(f\"prob = {prob}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(obs):\n",
    "    left_prob = model.predict(obs[np.newaxis])\n",
    "    action = int(np.random.rand() > left_prob)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards = 32.0\n"
     ]
    }
   ],
   "source": [
    "rewards, frames = play_one_episode(policy, render=True, seed=SEED)\n",
    "print(f\"rewards = {rewards}\")\n",
    "# plot_animation(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4999, loss: 0.080"
     ]
    }
   ],
   "source": [
    "NUM_ENVS = 50\n",
    "NUM_ITERS = 5000\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "envs = [gym.make(\"CartPole-v1\") for _ in range(NUM_ENVS)]\n",
    "for index, env in enumerate(envs):\n",
    "    env.seed(index)\n",
    "\n",
    "observations = [env.reset() for env in envs]\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "loss_fn = keras.losses.binary_crossentropy\n",
    "\n",
    "for i in range(NUM_ITERS):\n",
    "    # if angle < 0, we want prob(left) = 1., or else proba(left) = 0.\n",
    "    target_left_probs = np.array([([1.] if obs[2] < 0 else [0.]) for obs in observations])\n",
    "    with tf.GradientTape() as tape:\n",
    "        predict_left_probs = model(np.array(observations))\n",
    "        loss = tf.reduce_mean(loss_fn(target_left_probs, predict_left_probs))\n",
    "    print(\"\\rIteration: {}, loss: {:.3f}\".format(i, loss.numpy()), end=\"\")\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    actions = (np.random.rand(NUM_ENVS, 1) > predict_left_probs.numpy()).astype(np.int32)\n",
    "    for env_index, env in enumerate(envs):\n",
    "        obs, reward, done, info = env.step(actions[env_index][0])\n",
    "        observations[env_index] = obs if not done else env.reset()\n",
    "        \n",
    "for env in envs:\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards = 38.0\n"
     ]
    }
   ],
   "source": [
    "rewards, frames = play_one_episode(policy, True)\n",
    "print(f\"rewards = {rewards}\")\n",
    "# plot_animation(frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
