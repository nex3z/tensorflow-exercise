{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 28\n",
    "IMAGE_CHANNEL_NUM = 1\n",
    "\n",
    "CONV_1_DEPTH = 32\n",
    "CONV_1_SIZE = 5\n",
    "\n",
    "CONV_2_DEPTH = 64\n",
    "CONV_2_SIZE = 5\n",
    "\n",
    "FC_SIZE = 1024\n",
    "\n",
    "OUTPUT_SIZE = 10\n",
    "\n",
    "DROP_OUT_RATE = 0.4\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 100\n",
    "TRAINING_STEPS = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_layer(input_tensor, filter_depth, filter_size):\n",
    "    return tf.layers.conv2d(\n",
    "        inputs=input_tensor, \n",
    "        filters=filter_depth, \n",
    "        kernel_size=[filter_size, filter_size], \n",
    "        padding=\"same\", activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_max_polling_layer(input_tensor):\n",
    "    return tf.layers.max_pooling2d(input_tensor, pool_size=[2, 2], strides=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fc_layer(input_tensor, size, activation=tf.nn.relu):\n",
    "    return tf.layers.dense(input_tensor, units=size, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dropout_layer(input_tensor, rate, mode):\n",
    "    return tf.layers.dropout(\n",
    "        input_tensor, rate=rate, training=mode == tf.estimator.ModeKeys.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_model(features, labels, mode):\n",
    "    input_tensor = tf.reshape(features[\"x\"], [-1, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNEL_NUM])\n",
    "    conv_1 = create_conv_layer(input_tensor, CONV_1_DEPTH, CONV_1_SIZE)\n",
    "    pool_1 = create_max_polling_layer(conv_1)\n",
    "    conv_2 = create_conv_layer(pool_1, CONV_2_DEPTH, CONV_2_SIZE)\n",
    "    pool_2 = create_max_polling_layer(conv_2)\n",
    "    poll_2_shape = pool_2.get_shape().as_list()\n",
    "    pool_2_reshape = tf.reshape(pool_2, [-1, poll_2_shape[1] * poll_2_shape[2] * poll_2_shape[3]])\n",
    "    fc = create_fc_layer(pool_2_reshape, FC_SIZE)\n",
    "    dropout = create_dropout_layer(fc, DROP_OUT_RATE, mode)\n",
    "    logits = create_fc_layer(dropout, OUTPUT_SIZE, activation=None)\n",
    "    \n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(logits, axis=1),\n",
    "        \"probablities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(LEARNING_RATE)\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './tmp/mnist_conv', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x116055cf8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./tmp/mnist_conv/model.ckpt.\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:loss = 2.2896297, step = 1\n",
      "INFO:tensorflow: (22.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.28723\n",
      "INFO:tensorflow: (20.760 sec)\n",
      "INFO:tensorflow:loss = 1.9594587, step = 101 (43.723 sec)\n",
      "INFO:tensorflow: (21.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.32045\n",
      "INFO:tensorflow: (21.830 sec)\n",
      "INFO:tensorflow:loss = 0.73156536, step = 201 (43.095 sec)\n",
      "INFO:tensorflow: (23.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.42315\n",
      "INFO:tensorflow: (18.169 sec)\n",
      "INFO:tensorflow:loss = 0.49382618, step = 301 (41.270 sec)\n",
      "INFO:tensorflow: (11.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.88884\n",
      "INFO:tensorflow: (14.086 sec)\n",
      "INFO:tensorflow:loss = 0.39235544, step = 401 (25.712 sec)\n",
      "INFO:tensorflow: (18.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00871\n",
      "INFO:tensorflow: (14.485 sec)\n",
      "INFO:tensorflow:loss = 0.22854091, step = 501 (33.237 sec)\n",
      "INFO:tensorflow: (12.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.91371\n",
      "INFO:tensorflow: (12.824 sec)\n",
      "INFO:tensorflow:loss = 0.3745254, step = 601 (25.551 sec)\n",
      "INFO:tensorflow: (13.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.19319\n",
      "INFO:tensorflow: (17.474 sec)\n",
      "INFO:tensorflow:loss = 0.17150357, step = 701 (31.321 sec)\n",
      "INFO:tensorflow: (18.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.88312\n",
      "INFO:tensorflow: (16.602 sec)\n",
      "INFO:tensorflow:loss = 0.2959481, step = 801 (34.684 sec)\n",
      "INFO:tensorflow: (17.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.83475\n",
      "INFO:tensorflow: (17.616 sec)\n",
      "INFO:tensorflow:loss = 0.22321677, step = 901 (35.273 sec)\n",
      "INFO:tensorflow: (18.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.70943\n",
      "INFO:tensorflow: (18.476 sec)\n",
      "INFO:tensorflow:loss = 0.16871378, step = 1001 (36.910 sec)\n",
      "INFO:tensorflow: (15.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.44795\n",
      "INFO:tensorflow: (13.678 sec)\n",
      "INFO:tensorflow:loss = 0.17614986, step = 1101 (29.001 sec)\n",
      "INFO:tensorflow: (11.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.2038\n",
      "INFO:tensorflow: (12.358 sec)\n",
      "INFO:tensorflow:loss = 0.24482284, step = 1201 (23.790 sec)\n",
      "INFO:tensorflow: (12.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27047\n",
      "INFO:tensorflow: (11.143 sec)\n",
      "INFO:tensorflow:loss = 0.10624175, step = 1301 (23.415 sec)\n",
      "INFO:tensorflow: (10.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.60701\n",
      "INFO:tensorflow: (10.840 sec)\n",
      "INFO:tensorflow:loss = 0.20555258, step = 1401 (21.706 sec)\n",
      "INFO:tensorflow: (10.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.60463\n",
      "INFO:tensorflow: (10.854 sec)\n",
      "INFO:tensorflow:loss = 0.21300615, step = 1501 (21.717 sec)\n",
      "INFO:tensorflow: (10.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.61535\n",
      "INFO:tensorflow: (10.865 sec)\n",
      "INFO:tensorflow:loss = 0.18298133, step = 1601 (21.667 sec)\n",
      "INFO:tensorflow: (11.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.0014\n",
      "INFO:tensorflow: (13.345 sec)\n",
      "INFO:tensorflow:loss = 0.11404187, step = 1701 (24.992 sec)\n",
      "INFO:tensorflow: (14.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.83292\n",
      "INFO:tensorflow: (11.999 sec)\n",
      "INFO:tensorflow:loss = 0.14514546, step = 1801 (26.089 sec)\n",
      "INFO:tensorflow: (11.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.20453\n",
      "INFO:tensorflow: (11.785 sec)\n",
      "INFO:tensorflow:loss = 0.14308281, step = 1901 (23.784 sec)\n",
      "INFO:tensorflow: (12.109 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./tmp/mnist_conv/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0763164.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-21-14:04:05\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/mnist_conv/model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-21-14:04:13\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9696, global_step = 2000, loss = 0.1046143\n",
      "{'accuracy': 0.9696, 'loss': 0.1046143, 'global_step': 2000}\n"
     ]
    }
   ],
   "source": [
    "train_data = mnist.train.images\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "mnist_classifier = tf.estimator.Estimator(model_fn=mnist_model, model_dir=\"./tmp/mnist_conv\")\n",
    "# tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "tensors_to_log = {}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "mnist_classifier.train(input_fn=train_input_fn, steps=TRAINING_STEPS, hooks=[logging_hook])\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow36]",
   "language": "python",
   "name": "conda-env-tensorflow36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
